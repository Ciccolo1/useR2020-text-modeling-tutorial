---
title: "Predictive modeling with text using tidy data principles"
subtitle: "useR2020"
author: "Julia Silge & Emil Hvitfeldt"
date: "2019-7-24"
output:
  xaringan::moon_reader:
    css: ["default", "theme.css"]
    lib_dir: libs
    nature:
      highlightLanguage: "r"
      beforeInit: "macros.js"
      ratio: "16:9"
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      titleSlideClass: [center, middle]
---

```{r, eval = FALSE, echo = FALSE}
The general outline of the talk is:

Introduction
Motivation
talk about data
Start modeling
side tangent - talk about one of chapter 1-5
more modeling
side tangent - talk about one of chapter 1-5
finish modeling
evaluate

We will be doing 1 model workflow from start to finish, with sidestepping to talk about chapter 1-5 things

```


```{r include=FALSE}
library(knitr)
hook_output <- knit_hooks$get("output")
knit_hooks$set(output = function(x, options) {
  lines <- options$output.lines
  if (is.null(lines)) {
    return(hook_output(x, options))  # pass to default hook
  }
  x <- unlist(strsplit(x, "\n"))
  more <- "..."
  if (length(lines) == 1) {        # first n lines
    if (length(x) > lines) {
      # truncate the output, but add ....
      x <- c(head(x, lines), more)
    }
  } else {
    x <- c(more, x[lines], more)
  }
  # paste these lines together
  x <- paste(c(x, ""), collapse = "\n")
  hook_output(x, options)
})
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})

opts_chunk$set(
  echo = TRUE,
  fig.width = 7, 
  fig.align = 'center',
  fig.asp = 0.618, # 1 / phi
  out.width = "700px",
  fig.retina = 3)
```

```{r, echo = FALSE}
library(sass)
sass(sass_file("theme.sass"), output = "theme.css")
set.seed(1234)
library(ggplot2)
theme_set(theme_minimal())
```

class: center, middle

# Hello!

.pull-left[
<img style="border-radius: 50%;" src="https://github.com/EmilHvitfeldt.png" width="150px"/>  
[`r icon::fa("github")` @EmilHvitfeldt](https://github.com/EmilHvitfeldt)  
[`r icon::fa("twitter")` @Emil_Hvitfeldt](https://twitter.com/Emil_Hvitfeldt)  
[`r icon::fa("link")` hvitfeldt.me](https://www.hvitfeldt.me/)
]

.pull-right[
<img style="border-radius: 50%;" src="https://github.com/juliasilge.png" width="150px"/>  
[`r icon::fa("github")` @juliasilge](https://github.com/juliasilge)  
[`r icon::fa("twitter")` @juliasilge](https://twitter.com/juliasilge)  
[`r icon::fa("link")` juliasilge.com](https://juliasilge.com)
]
---

# Plan for today

--

- We will walk through our case study using slides and live coding



--


- After the tutorial, use the [materials on GitHub](https://github.com/EmilHvitfeldt/useR2020-text-modeling-tutorial) and YouTube recording to run the code yourself `r emo::ji("muscle")`

---

# Text as data

Let's look at complaints submitted to the [United States Consumer Financial Protection Bureau (CFPB)](https://www.consumerfinance.gov/data-research/consumer-complaints/).

--


- An individual experiences a problem `r emo::ji("weary")` with a consumer financial product or service, like a bank, loan, or credit card `r emo::ji("moneybag")`


--


- They submit a **complaint** to the CFPB explaining what happened `r emo::ji("rage")`


--


- This complaint is sent to the company, which can respond or dispute


---

# Text as data

Let's look at complaints submitted to the [United States Consumer Financial Protection Bureau (CFPB)](https://www.consumerfinance.gov/data-research/consumer-complaints/).

```{r R.options = list(width = 80), message=FALSE}
library(tidyverse)

complaints <- read_csv("data/complaints.csv.gz") %>% sample_frac(0.005)
names(complaints)
```

---

# Text as data

```{r}
complaints %>%
  sample_n(10) %>%
  pull(consumer_complaint_narrative)
```

---

# Modeling Packages

```{r}
library(tidymodels)
library(textrecipes)
```

- [tidymodels](https://www.tidymodels.org/) is a collection of packages for modeling and machine learning using tidyverse principles
- [textrecipes](https://textrecipes.tidymodels.org/) extends the recipes package to handle text preprocessing

---

# Modeling workflow

![](https://rviews.rstudio.com/post/2019-06-14-a-gentle-intro-to-tidymodels_files/figure-html/tidymodels.png)

---

# Modeling workflow

```{r echo=FALSE, out.width="100%"}
knitr::include_url("https://smltar.com/")
```

---

# Class imbalance

```{r, echo=FALSE}
complaints %>%
  mutate(product = str_wrap(product, 50),
         product = fct_rev(fct_infreq(factor(product)))) %>%
  ggplot(aes(y = product)) +
  geom_bar() +
  labs(x = NULL, y = NULL)
```

---

class: inverse, right, middle

# Let's approach this as a **binary classification task**

---

# Credit or not?

```{r}
credit <- "Credit reporting, credit repair services, or other personal consumer reports"

complaints2class <- complaints %>%
  mutate(product = factor(if_else(
    condition = product == credit, 
    true = "Credit", 
    false = "Other"))) %>%
  rename(text = consumer_complaint_narrative)
```

---

# Data splitting

Split our data into **training** and **testing**

```{r all-split, echo = FALSE, fig.width=10}
set.seed(16)
one_split <- slice(complaints2class, 1:30) %>% 
  initial_split() %>% 
  tidy() %>% 
  add_row(Row = 1:30, Data = "Original") %>% 
  mutate(Data = case_when(
    Data == "Analysis" ~ "Training",
    Data == "Assessment" ~ "Testing",
    TRUE ~ Data
  )) %>% 
  mutate(Data = factor(Data, levels = c("Original", "Training", "Testing")))

all_split <-
  ggplot(one_split, aes(x = Row, y = fct_rev(Data), fill = Data)) + 
  geom_tile(color = "white",
            size = 1) + 
  #scale_fill_manual(values = splits_pal, guide = FALSE) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = rel(2)),
        axis.text.x = element_blank(),
        legend.position = "top",
        panel.grid = element_blank()) +
  coord_equal(ratio = 1) +
  labs(x = NULL, y = NULL)

all_split
```

---

# Data splitting


```{r}
set.seed(1234)

complaints_split <- initial_split(complaints2class, strata = product)

complaints_train <- training(complaints_split)
complaints_test <- testing(complaints_split)
```

---

# Which of these variables can we use?

```{r}
names(complaints_train)
```

---

# Feature selection checklist

--


- Is it ethical to use this variable? (or even legal?)


--


- Will this variable be available at prediction time?


--


- Does this variable contribute to explainability?

---

# Which of these variables can we use?

```{r}
names(complaints_train)
```

---

# Which of these variables can we use?

- `date_received`
- `tags`
- `consumer_complaint_narrative` == `r emo::ji("page_with_curl")`

---

# Preprocessing specification

```{r}
complaints_rec <-
  recipe(product ~ date_received + tags + text,
    data = complaints_train
  ) %>%
  step_date(date_received, features = c("month", "dow"), role = "dates") %>%
  step_rm(date_received) %>%
  step_dummy(has_role("dates")) %>%
  step_unknown(tags) %>%
  step_dummy(tags) %>%
  step_tokenize(text) %>%
  step_stopwords(text) %>%
  step_ngram(text, num_tokens = 3, min_num_tokens = 1) %>%
  step_tokenfilter(text, max_tokens = tune(), min_times = 5) %>%
  step_tfidf(text)
```

---

TODO:

talk about preprocessing step by step


---

# Let's talk about stopwords!

---


# Model specification

```{r}
lasso_spec <- logistic_reg(penalty = tune(), mixture = 1) %>%
  set_mode("classification") %>%
  set_engine("glmnet")


lasso_spec
```

---

# Creating a workflow

```{r}
wf_spec <- workflow() %>%
  add_recipe(complaints_rec) %>%
  add_model(lasso_spec)
```

---

# Setting up a tuning grid

```{r}
param_grid <- grid_regular(
  penalty(range = c(-4, 0)),
  max_tokens(range = c(500, 2000)),
  levels = 6
)


param_grid
```

---


```{r}
complaints_folds <- vfold_cv(complaints_train, v = 2)

complaints_folds
```

---

```{r}
set.seed(42)
lasso_grid <- tune_grid(
  wf_spec,
  resamples = complaints_folds,
  grid = param_grid, control = control_grid(verbose = TRUE)
) 
```

---

# lets talk about tokenization

(this feels like an okay segway since using n-grams)

---

# Looking at the hyperparameters

```{r}
autoplot(lasso_grid)
```

---

# Looking at the hyperparameters

```{r}
lasso_grid %>%
  show_best("accuracy")
```

---

# update workflow

```{r}
wf_spec_final <- wf_spec %>%
  finalize_workflow(parameters = select_best(lasso_grid, "accuracy"))
```

---

# Final fit

```{r}
final_fit <- last_fit(object = wf_spec_final, 
                      split = complaints_split, 
                      metrics = metric_set(accuracy))
```

```{r}
final_fit %>%
  collect_predictions() %>%
  conf_mat(product, .pred_class)
```

---

# Variable importance - how is our model thinking

```{r, echo=FALSE}
wi_data <- wf_spec_final %>%
  fit(complaints_train) %>%
  pull_workflow_fit() %>%
  vip::vi(lambda = select_best(lasso_grid, "roc_auc")$penalty) %>%
  mutate(Variable = stringr::str_remove_all(Variable, "tfidf_text_")) %>%
  filter(Importance != 0)

wi_data %>%
  mutate(
    Importance = abs(Importance)
    ) %>%
  filter(Importance != 0) %>%
  group_by(Sign) %>%
  top_n(20, Importance) %>%
  ungroup() %>%
  ggplot(aes(
    x = Importance,
    y = forcats::fct_reorder(Variable, Importance),
    fill = Sign
  )) +
  geom_col(show.legend = FALSE) +
  scale_x_continuous(expand = c(0, 0)) +
  facet_wrap(~Sign, scales = "free") +
  labs(
    y = NULL,
    title = "Variable importance for predicting year of Supreme Court opinions",
    subtitle = "These features are the most importance in predicting the year of an opinion"
  )
```

---

```{r, echo=FALSE}
highlighter <- function(x, sign) {
  if(is.na(sign)) {
    htmltools::span(x)
  } else if (sign == "NEG") {
    htmltools::span(x, style = 'color:green;')
  } else if (sign == "POS") {
    htmltools::span(x, style = 'color:blue;')
  }
}
```

## Credit Complaint #1

<span, style = 'color:green;'>Credit</span>
<span, style = 'color:black;'>And</span>
<span, style = 'color:blue;'>Other</span>

```{r, echo=FALSE}
complaints_train %>%
  filter(product == "Credit", nchar(text) < 800) %>%
  slice(1) %>%
  tidytext::unnest_tokens(words, text) %>%
  left_join(wi_data, by = c("words" = "Variable")) %>%
  mutate(words = map2(words, Sign, highlighter)) %>%
  pull(words) %>%
  htmltools::div()
```

---

## Credit Complaint #2

<span, style = 'color:green;'>Credit</span>
<span, style = 'color:black;'>And</span>
<span, style = 'color:blue;'>Other</span>

```{r, echo=FALSE}
complaints_train %>%
  filter(product == "Credit", nchar(text) < 800) %>%
  slice(2) %>%
  tidytext::unnest_tokens(words, text) %>%
  left_join(wi_data, by = c("words" = "Variable")) %>%
  mutate(words = map2(words, Sign, highlighter)) %>%
  pull(words) %>%
  htmltools::div()
```

---

## Other Complaint #1

<span, style = 'color:green;'>Credit</span>
<span, style = 'color:black;'>And</span>
<span, style = 'color:blue;'>Other</span>

```{r, echo=FALSE}
complaints_train %>%
  filter(product == "Other", nchar(text) < 800) %>%
  slice(1) %>%
  tidytext::unnest_tokens(words, text) %>%
  left_join(wi_data, by = c("words" = "Variable")) %>%
  mutate(words = map2(words, Sign, highlighter)) %>%
  pull(words) %>%
  htmltools::div()
```

---

## Other Complaint #2

<span, style = 'color:green;'>Credit</span>
<span, style = 'color:black;'>And</span>
<span, style = 'color:blue;'>Other</span>

```{r, echo=FALSE}
complaints_train %>%
  filter(product == "Other", nchar(text) < 800) %>%
  slice(2) %>%
  tidytext::unnest_tokens(words, text) %>%
  left_join(wi_data, by = c("words" = "Variable")) %>%
  mutate(words = map2(words, Sign, highlighter)) %>%
  pull(words) %>%
  htmltools::div()
```

---

